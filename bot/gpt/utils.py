import logging

from aiogram.enums import ParseMode
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton

from bot.main_keyboard import send_message
from services.gpt_service import GPTModels
import telegramify_markdown

def checked_text(value: str):
    return f"‚úÖ {value}"

def get_model_text(model: GPTModels, current_model: GPTModels):
    if model.value == current_model.value:
        return checked_text(model.value)

    return model.value

def get_model_description(model: GPTModels) -> str:
    """Get detailed description for a model including capabilities and data cutoff"""
    descriptions = {
        GPTModels.O3_mini: "üöÄ O3-mini - –ù–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å OpenAI —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.O1_preview: "üß† O1-preview - –ú–æ–¥–µ–ª—å —Å –≥–ª—É–±–æ–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º, –ª—É—á—à–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.O1_mini: "üí° O1-mini - –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è O1 –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.DeepSeek_Chat: "üí¨ DeepSeek Chat - –ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ (–¥–∞–Ω–Ω—ã–µ –¥–æ 2023)",
        GPTModels.DeepSeek_Reasoner: "üîç DeepSeek Reasoner - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö (–¥–∞–Ω–Ω—ã–µ –¥–æ 2023)",
        GPTModels.Claude_3_5_Sonnet: "üé≠ Claude 3.5 Sonnet - –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á (–¥–∞–Ω–Ω—ã–µ –¥–æ –∞–ø—Ä–µ–ª—è 2024)",
        GPTModels.Claude_3_7_Sonnet: "üé≠ Claude 3.7 Sonnet - –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ª—É—á—à–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥–∞–Ω–Ω—ã–µ –¥–æ –∞–ø—Ä–µ–ª—è 2024)",
        GPTModels.Claude_3_Opus: "üé® Claude 3 Opus - –°–∞–º–∞—è –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å Claude –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á (–¥–∞–Ω–Ω—ã–µ –¥–æ –∞–≤–≥—É—Å—Ç–∞ 2023)",
        GPTModels.Claude_3_5_Haiku: "‚ö° Claude 3.5 Haiku - –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á (–¥–∞–Ω–Ω—ã–µ –¥–æ –∏—é–ª—è 2024)",
        GPTModels.GPT_Auto: "üîÑ GPT Auto - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π GPT –º–æ–¥–µ–ª–∏ (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.GPT_4_Unofficial: "üåê GPT-4 Unofficial - –ù–µ–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4 (–¥–∞–Ω–Ω—ã–µ –¥–æ –∞–ø—Ä–µ–ª—è 2023)",
        GPTModels.GPT_4o: "üöÄ GPT-4o - –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å OpenAI (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.GPT_4o_mini: "üíé GPT-4o mini - –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è GPT-4o (–¥–∞–Ω–Ω—ã–µ –¥–æ –æ–∫—Ç—è–±—Ä—è 2023)",
        GPTModels.GPT_3_5: "‚ö° GPT-3.5 - –ë—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å (–¥–∞–Ω–Ω—ã–µ –¥–æ —Å–µ–Ω—Ç—è–±—Ä—è 2021)",
        GPTModels.Llama3_1_405B: "ü¶ô Llama 3.1 405B - –ú–æ—â–Ω–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å Meta (–¥–∞–Ω–Ω—ã–µ –¥–æ –¥–µ–∫–∞–±—Ä—è 2023)",
        GPTModels.Llama3_1_70B: "ü¶ô Llama 3.1 70B - –°—Ä–µ–¥–Ω—è—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å Meta (–¥–∞–Ω–Ω—ã–µ –¥–æ –¥–µ–∫–∞–±—Ä—è 2023)",
        GPTModels.Llama3_1_8B: "ü¶ô Llama 3.1 8B - –ë—ã—Å—Ç—Ä–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å Meta (–¥–∞–Ω–Ω—ã–µ –¥–æ –¥–µ–∫–∞–±—Ä—è 2023)",
        GPTModels.Llama_3_70b: "ü¶ô Llama 3 70B - –ü—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ä—Å–∏—è –æ—Ç Meta (–¥–∞–Ω–Ω—ã–µ –¥–æ –º–∞—Ä—Ç–∞ 2024)",
        GPTModels.Uncensored: "üîì Uncensored - –ú–æ–¥–µ–ª—å –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–¥–∞–Ω–Ω—ã–µ –¥–æ 2023)"
    }
    return descriptions.get(model, f"üìñ {model.value} - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å")


subscribe_text = """
üì∞ –ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –Ω–∞—à –∫–∞–Ω–∞–ª! @gptDeep

–°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ —É –Ω–∞—Å –≤ –∫–∞–Ω–∞–ª–µ!
"""


async def check_subscription(message: Message, id: str = None) -> bool:
    user_id = id if id is not None else message.from_user.id

    chat_member = await message.bot.get_chat_member(chat_id=-1002239712203, user_id=user_id)

    check_result = chat_member.status in ['member', 'administrator', 'creator']

    print(f"User {user_id} is subscribed as: {check_result}")

    return check_result


async def is_chat_member(message: Message) -> bool:
    is_subscribe = await check_subscription(message)

    if not is_subscribe:
        await message.answer(
            text=subscribe_text,
            reply_markup=InlineKeyboardMarkup(
                resize_keyboard=True,
                inline_keyboard=[[InlineKeyboardButton(text="–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∫–∞–Ω–∞–ª", url="https://t.me/gptDeep")]]
            )
        )

    return is_subscribe


def get_tokens_message(tokens_spent: int, tokens_left: int, requested_model: str = None, responded_model: str = None):
    if tokens_spent <= 0:
        return None
    
    if responded_model and (requested_model == responded_model):
        return f"""ü§ñ –û—Ç–≤–µ—Ç –æ—Ç: *{responded_model}*

‚ú® –ó–∞—Ç—Ä–∞—á–µ–Ω–æ: *{tokens_spent}‚ö°Ô∏è* (–æ—Å—Ç–∞–ª–æ—Å—å *{tokens_left}‚ö°Ô∏è*)"""
    elif requested_model and responded_model:
        return f"""ü§ñ –û—Ç–≤–µ—Ç –æ—Ç: *{responded_model}*
‚ö†Ô∏è –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å *{requested_model}* –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!

‚ú® –ó–∞—Ç—Ä–∞—á–µ–Ω–æ: *{tokens_spent}‚ö°Ô∏è* (–æ—Å—Ç–∞–ª–æ—Å—å *{tokens_left}‚ö°Ô∏è*)"""
    elif requested_model:
        return f"""ü§ñ –û—Ç–≤–µ—Ç –æ—Ç: *{requested_model}* (–Ω–æ —ç—Ç–æ *–Ω–µ —Ç–æ—á–Ω–æ*)
‚ö†Ô∏è –ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–∞–ø–∏—à–∏—Ç–µ –æ–± —ç—Ç–æ–º –≤ —Ä–∞–∑–¥–µ–ª–µ *–û—à–∏–±–∫–∏* –≤ –Ω–∞—à–µ–º —Å–æ–±—â–µ—Å—Ç–≤–µ @deepGPT.

‚ú® –ó–∞—Ç—Ä–∞—á–µ–Ω–æ: *{tokens_spent}‚ö°Ô∏è* (–æ—Å—Ç–∞–ª–æ—Å—å *{tokens_left}‚ö°Ô∏è*)"""
    else:
        return f"""ü§ñ –û—Ç–≤–µ—Ç –æ—Ç: *–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ* (–Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å)
‚ö†Ô∏è –ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–∞–ø–∏—à–∏—Ç–µ –æ–± —ç—Ç–æ–º –≤ —Ä–∞–∑–¥–µ–ª–µ *–û—à–∏–±–∫–∏* –≤ –Ω–∞—à–µ–º —Å–æ–±—â–µ—Å—Ç–≤–µ @deepGPT.

‚ú® –ó–∞—Ç—Ä–∞—á–µ–Ω–æ: *{tokens_spent}‚ö°Ô∏è* (–æ—Å—Ç–∞–ª–æ—Å—å *{tokens_left}‚ö°Ô∏è*)"""


def split_message(message):
    max_symbols = 3990
    messages = []
    current_message = ''
    current_language = ''
    in_code_block = False
    lines = message.split('\n')

    for line in lines:
        is_code_block_line = line.startswith('```')
        if is_code_block_line:
            current_language = line[3:].strip()
            in_code_block = not in_code_block

        potential_message = (current_message + '\n' if current_message else '') + line

        if len(potential_message) > max_symbols:
            if in_code_block:
                current_message += '\n```'

            messages.append(current_message)

            if in_code_block:
                current_message = f'```{current_language}\n{line}'
            else:
                current_message = line
        else:
            current_message = potential_message

    if current_message:
        if in_code_block:
            current_message += '\n```'
        messages.append(current_message)

    return messages

async def send_markdown_message(message: Message, text: str):
    parts = split_message(text)
    for i, part in enumerate(parts):
        try:
            # Add continue button only to the last part of the message
            if i == len(parts) - 1:
                continue_keyboard = InlineKeyboardMarkup(
                    inline_keyboard=[[
                        InlineKeyboardButton(
                            text="‚û°Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å",
                            callback_data="continue_response"
                        )
                    ]]
                )
                await send_message(message, text=telegramify_markdown.markdownify(part), parse_mode=ParseMode.MARKDOWN_V2, reply_markup=continue_keyboard)
            else:
                await send_message(message, text=telegramify_markdown.markdownify(part), parse_mode=ParseMode.MARKDOWN_V2)
        except Exception as e:
            if i == len(parts) - 1:
                continue_keyboard = InlineKeyboardMarkup(
                    inline_keyboard=[[
                        InlineKeyboardButton(
                            text="‚û°Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å",
                            callback_data="continue_response"
                        )
                    ]]
                )
                await send_message(message, text=part, parse_mode=None, reply_markup=continue_keyboard)
            else:
                await send_message(message, text=part, parse_mode=None)
            logging.error(f"Failed to send message as markdown: {e}")
    return parts

def create_change_model_keyboard(current_model: GPTModels):
    return InlineKeyboardMarkup(resize_keyboard=True, inline_keyboard=[
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.O3_mini, current_model),
                callback_data=GPTModels.O3_mini.value
            )
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.O1_preview, current_model),
                callback_data=GPTModels.O1_preview.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.O1_mini, current_model),
                callback_data=GPTModels.O1_mini.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.DeepSeek_Chat, current_model),
                callback_data=GPTModels.DeepSeek_Chat.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.DeepSeek_Reasoner, current_model),
                callback_data=GPTModels.DeepSeek_Reasoner.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Claude_3_5_Sonnet, current_model),
                callback_data=GPTModels.Claude_3_5_Sonnet.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Claude_3_7_Sonnet, current_model),
                callback_data=GPTModels.Claude_3_7_Sonnet.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Claude_3_Opus, current_model),
                callback_data=GPTModels.Claude_3_Opus.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Claude_3_5_Haiku, current_model),
                callback_data=GPTModels.Claude_3_5_Haiku.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.GPT_Auto, current_model),
                callback_data=GPTModels.GPT_Auto.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.GPT_4_Unofficial, current_model),
                callback_data=GPTModels.GPT_4_Unofficial.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.GPT_4o, current_model),
                callback_data=GPTModels.GPT_4o.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.GPT_4o_mini, current_model),
                callback_data=GPTModels.GPT_4o_mini.value
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.GPT_3_5, current_model),
                callback_data=GPTModels.GPT_3_5.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Llama3_1_405B, current_model),
                callback_data=GPTModels.Llama3_1_405B.value
            )
        ],
        [
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Llama3_1_70B, current_model),
                callback_data=GPTModels.Llama3_1_70B.value
            ),
            InlineKeyboardButton(
                text=get_model_text(GPTModels.Llama3_1_8B, current_model),
                callback_data=GPTModels.Llama3_1_8B.value
            ),
        ]
    ])
